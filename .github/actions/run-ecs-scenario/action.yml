name: 'Run Omes Scenario on ECS'
description: 'Runs an omes scenario on ECS Fargate against Temporal Cloud'

inputs:
  # SDK Configuration
  language:
    description: 'SDK language (go, java, python, dotnet, typescript)'
    required: true
  sdk-repo:
    description: 'SDK repository (e.g., temporalio/sdk-go)'
    required: true
  sdk-gitref:
    description: 'SDK git ref (commit, tag, or branch) to test'
    required: true

  # Scenario Configuration
  scenario:
    description: 'Omes scenario to run'
    required: false
    default: 'throughput_stress'
  run-id:
    description: 'Unique run identifier'
    required: true
  duration:
    description: 'Test duration (e.g., 5h, 1h)'
    required: false
    default: '5h'
  timeout:
    description: 'Scenario timeout (should be greater than duration)'
    required: false
    default: '5h30m'
  max-concurrent:
    description: 'Maximum concurrent workflows'
    required: false
    default: '10'
  scenario-options:
    description: 'Additional scenario options as JSON array (e.g., ["internal-iterations=10", "sleep-time=1s"])'
    required: false
    default: '["internal-iterations=10", "continue-as-new-after-iterations=3", "sleep-time=1s", "visibility-count-timeout=5m", "min-throughput-per-hour=1000"]'

  # Temporal Cloud Configuration
  temporal-cloud-namespace:
    description: 'Temporal Cloud namespace (e.g., my-ns.abc123)'
    required: true
  temporal-cloud-address:
    description: 'Temporal Cloud address (e.g., my-ns.abc123.tmprl.cloud:7233)'
    required: true
  temporal-cloud-api-key-secret-arn:
    description: 'ARN of Secrets Manager secret containing Temporal API key'
    required: true

  # AWS Configuration
  aws-region:
    description: 'AWS region'
    required: false
    default: 'us-west-2'
  ecs-cluster:
    description: 'ECS cluster name'
    required: true
  ecr-repository:
    description: 'ECR repository name'
    required: true
  vpc-subnets:
    description: 'Comma-separated list of VPC subnet IDs'
    required: true
  vpc-security-groups:
    description: 'Comma-separated list of security group IDs'
    required: true

  # Image Configuration
  build-images:
    description: 'Whether to build and push images (true) or use existing (false)'
    required: false
    default: 'true'
  worker-image-tag:
    description: 'Worker image tag (used when build-images=false)'
    required: false
    default: ''
  client-image-tag:
    description: 'Client image tag (defaults to omes-client-latest)'
    required: false
    default: 'omes-client-latest'

  # S3 Metrics Upload
  s3-metrics-bucket:
    description: 'S3 bucket for metrics upload'
    
    required: false
    default: 'cloud-data-ingest-prod'
  s3-metrics-prefix:
    description: 'S3 prefix for metrics'
    required: false
    default: 'github/sdk_load_test'
  is-experiment:
    description: 'Mark this run as an experiment'
    required: false
    default: 'false'

outputs:
  worker-task-arn:
    description: 'ARN of the worker ECS task'
    value: ${{ steps.start-worker.outputs.task-arn }}
  client-task-arn:
    description: 'ARN of the client ECS task'
    value: ${{ steps.start-client.outputs.task-arn }}
  metrics-s3-path:
    description: 'S3 path where metrics were uploaded'
    value: ${{ steps.upload-metrics.outputs.s3-path }}

runs:
  using: composite
  steps:
    - name: Checkout Omes
      uses: actions/checkout@v4
      with:
        repository: temporalio/omes
        ref: main
        path: omes-repo

    - name: Setup Go (for building images)
      if: inputs.build-images == 'true'
      uses: actions/setup-go@v5
      with:
        go-version-file: omes-repo/go.mod
        cache-dependency-path: omes-repo/go.sum

    - name: Get AWS Account ID
      id: aws-account
      shell: bash
      run: |
        ACCOUNT_ID=$(aws sts get-caller-identity --query Account --output text)
        echo "account-id=$ACCOUNT_ID" >> $GITHUB_OUTPUT

    - name: Login to ECR
      shell: bash
      env:
        AWS_REGION: ${{ inputs.aws-region }}
        ACCOUNT_ID: ${{ steps.aws-account.outputs.account-id }}
      run: |
        aws ecr get-login-password --region $AWS_REGION | \
          docker login --username AWS --password-stdin $ACCOUNT_ID.dkr.ecr.$AWS_REGION.amazonaws.com

    - name: Checkout SDK
      if: inputs.build-images == 'true'
      uses: actions/checkout@v4
      with:
        repository: ${{ inputs.sdk-repo }}
        ref: ${{ inputs.sdk-gitref }}
        path: sdk-repo
        submodules: recursive

    - name: Build SDK (Python)
      if: inputs.build-images == 'true' && inputs.language == 'python'
      shell: bash
      working-directory: sdk-repo
      run: |
        pip install uv
        uv sync --all-extras
        uv run poe build-develop

    - name: Build SDK (TypeScript)
      if: inputs.build-images == 'true' && inputs.language == 'typescript'
      shell: bash
      working-directory: sdk-repo
      run: |
        npm install
        npm run build
      env:
        BUILD_CORE_RELEASE: true

    - name: Build SDK (Java)
      if: inputs.build-images == 'true' && inputs.language == 'java'
      shell: bash
      working-directory: sdk-repo
      run: ./gradlew build -x test -x virtualThreadTests

    - name: Build SDK (.NET)
      if: inputs.build-images == 'true' && inputs.language == 'dotnet'
      shell: bash
      working-directory: sdk-repo
      run: dotnet build
      env:
        ImportDirectoryBuildProps: false

    - name: Build and push worker image
      if: inputs.build-images == 'true'
      id: build-worker
      shell: bash
      working-directory: omes-repo
      env:
        LANGUAGE: ${{ inputs.language }}
        GITREF: ${{ inputs.sdk-gitref }}
        ECR_REPO: ${{ steps.aws-account.outputs.account-id }}.dkr.ecr.${{ inputs.aws-region }}.amazonaws.com/${{ inputs.ecr-repository }}
      run: |
        IMAGE_TAG="${LANGUAGE}-worker-${GITREF}"

        docker build \
          -f dockerfiles/${LANGUAGE}.Dockerfile \
          --build-arg SDK_DIR=../sdk-repo \
          --build-arg SDK_VERSION=./repo \
          -t $ECR_REPO:$IMAGE_TAG \
          .

        docker push $ECR_REPO:$IMAGE_TAG
        echo "image-tag=$IMAGE_TAG" >> $GITHUB_OUTPUT

    - name: Build and push client image
      if: inputs.build-images == 'true'
      shell: bash
      working-directory: omes-repo
      env:
        ECR_REPO: ${{ steps.aws-account.outputs.account-id }}.dkr.ecr.${{ inputs.aws-region }}.amazonaws.com/${{ inputs.ecr-repository }}
        CLIENT_TAG: ${{ inputs.client-image-tag }}
      run: |
        docker build \
          -f dockerfiles/cli-prometheus.Dockerfile \
          -t $ECR_REPO:$CLIENT_TAG \
          .

        docker push $ECR_REPO:$CLIENT_TAG

    - name: Determine image tags
      id: image-tags
      shell: bash
      env:
        BUILD_IMAGES: ${{ inputs.build-images }}
        BUILT_WORKER_TAG: ${{ steps.build-worker.outputs.image-tag }}
        INPUT_WORKER_TAG: ${{ inputs.worker-image-tag }}
        CLIENT_TAG: ${{ inputs.client-image-tag }}
        LANGUAGE: ${{ inputs.language }}
        GITREF: ${{ inputs.sdk-gitref }}
      run: |
        if [ "$BUILD_IMAGES" == "true" ]; then
          WORKER_TAG="$BUILT_WORKER_TAG"
        else
          WORKER_TAG="${INPUT_WORKER_TAG:-${LANGUAGE}-worker-${GITREF}}"
        fi
        echo "worker-tag=$WORKER_TAG" >> $GITHUB_OUTPUT
        echo "client-tag=$CLIENT_TAG" >> $GITHUB_OUTPUT

    - name: Start worker task
      id: start-worker
      shell: bash
      env:
        CLUSTER: ${{ inputs.ecs-cluster }}
        SUBNETS: ${{ inputs.vpc-subnets }}
        SECURITY_GROUPS: ${{ inputs.vpc-security-groups }}
        ECR_REPO: ${{ steps.aws-account.outputs.account-id }}.dkr.ecr.${{ inputs.aws-region }}.amazonaws.com/${{ inputs.ecr-repository }}
        WORKER_TAG: ${{ steps.image-tags.outputs.worker-tag }}
        TEMPORAL_ADDRESS: ${{ inputs.temporal-cloud-address }}
        TEMPORAL_NAMESPACE: ${{ inputs.temporal-cloud-namespace }}
        API_KEY_SECRET_ARN: ${{ inputs.temporal-cloud-api-key-secret-arn }}
        RUN_ID: ${{ inputs.run-id }}
        AWS_REGION: ${{ inputs.aws-region }}
      run: |
        TASK_ARN=$(aws ecs run-task \
          --cluster $CLUSTER \
          --task-definition omes-worker \
          --launch-type FARGATE \
          --network-configuration "awsvpcConfiguration={subnets=[$SUBNETS],securityGroups=[$SECURITY_GROUPS],assignPublicIp=ENABLED}" \
          --overrides "{
            \"containerOverrides\": [{
              \"name\": \"sdk-worker\",
              \"image\": \"$ECR_REPO:$WORKER_TAG\",
              \"command\": [
                \"--server-address\", \"$TEMPORAL_ADDRESS\",
                \"--namespace\", \"$TEMPORAL_NAMESPACE\",
                \"--tls\",
                \"--run-id\", \"$RUN_ID\",
                \"--worker-prom-listen-address\", \"0.0.0.0:9092\"
              ]
            }]
          }" \
          --query 'tasks[0].taskArn' \
          --output text)

        echo "task-arn=$TASK_ARN" >> $GITHUB_OUTPUT
        echo "Started worker task: $TASK_ARN"

    - name: Wait for worker and get IP
      id: worker-ip
      shell: bash
      env:
        CLUSTER: ${{ inputs.ecs-cluster }}
        TASK_ARN: ${{ steps.start-worker.outputs.task-arn }}
      run: |
        echo "Waiting for worker task to be running..."
        aws ecs wait tasks-running --cluster $CLUSTER --tasks $TASK_ARN

        WORKER_IP=$(aws ecs describe-tasks \
          --cluster $CLUSTER \
          --tasks $TASK_ARN \
          --query 'tasks[0].attachments[0].details[?name==`privateIPv4Address`].value' \
          --output text)

        echo "worker-ip=$WORKER_IP" >> $GITHUB_OUTPUT
        echo "Worker IP: $WORKER_IP"

    - name: Build scenario options
      id: scenario-opts
      shell: bash
      env:
        OPTIONS_JSON: ${{ inputs.scenario-options }}
      run: |
        # Convert JSON array to command args
        OPTIONS=$(echo "$OPTIONS_JSON" | jq -r '.[] | "--option", .')
        echo "options=$OPTIONS" >> $GITHUB_OUTPUT

    - name: Start client task
      id: start-client
      shell: bash
      env:
        CLUSTER: ${{ inputs.ecs-cluster }}
        SUBNETS: ${{ inputs.vpc-subnets }}
        SECURITY_GROUPS: ${{ inputs.vpc-security-groups }}
        ECR_REPO: ${{ steps.aws-account.outputs.account-id }}.dkr.ecr.${{ inputs.aws-region }}.amazonaws.com/${{ inputs.ecr-repository }}
        CLIENT_TAG: ${{ steps.image-tags.outputs.client-tag }}
        TEMPORAL_ADDRESS: ${{ inputs.temporal-cloud-address }}
        TEMPORAL_NAMESPACE: ${{ inputs.temporal-cloud-namespace }}
        API_KEY_SECRET_ARN: ${{ inputs.temporal-cloud-api-key-secret-arn }}
        RUN_ID: ${{ inputs.run-id }}
        SCENARIO: ${{ inputs.scenario }}
        DURATION: ${{ inputs.duration }}
        TIMEOUT: ${{ inputs.timeout }}
        MAX_CONCURRENT: ${{ inputs.max-concurrent }}
        WORKER_IP: ${{ steps.worker-ip.outputs.worker-ip }}
        OPTIONS_JSON: ${{ inputs.scenario-options }}
        AWS_REGION: ${{ inputs.aws-region }}
      run: |
        # Build options array for command
        OPTIONS_ARGS=$(echo "$OPTIONS_JSON" | jq -r '[.[] | "--option", .] | join("\", \"")' | sed 's/^/"/;s/$/"/')

        TASK_ARN=$(aws ecs run-task \
          --cluster $CLUSTER \
          --task-definition omes-client \
          --launch-type FARGATE \
          --network-configuration "awsvpcConfiguration={subnets=[$SUBNETS],securityGroups=[$SECURITY_GROUPS],assignPublicIp=ENABLED}" \
          --overrides "{
            \"containerOverrides\": [{
              \"name\": \"omes-client\",
              \"image\": \"$ECR_REPO:$CLIENT_TAG\",
              \"environment\": [
                {\"name\": \"WORKER_METRICS_HOST\", \"value\": \"$WORKER_IP\"},
                {\"name\": \"WORKER_METRICS_PORT\", \"value\": \"9092\"}
              ],
              \"command\": [
                \"run-scenario\",
                \"--server-address\", \"$TEMPORAL_ADDRESS\",
                \"--namespace\", \"$TEMPORAL_NAMESPACE\",
                \"--tls\",
                \"--scenario\", \"$SCENARIO\",
                \"--run-id\", \"$RUN_ID\",
                \"--duration\", \"$DURATION\",
                \"--timeout\", \"$TIMEOUT\",
                \"--max-concurrent\", \"$MAX_CONCURRENT\",
                \"--prom-listen-address\", \"0.0.0.0:9091\",
                \"--prom-instance-addr\", \"127.0.0.1:9090\",
                \"--prom-instance-config\", \"/app/prom-config.yml\",
                \"--prom-export-worker-metrics\", \"$RUN_ID.parquet\",
                $OPTIONS_ARGS
              ]
            }]
          }" \
          --query 'tasks[0].taskArn' \
          --output text)

        echo "task-arn=$TASK_ARN" >> $GITHUB_OUTPUT
        echo "Started client task: $TASK_ARN"

    - name: Wait for client to complete
      id: wait-client
      shell: bash
      env:
        CLUSTER: ${{ inputs.ecs-cluster }}
        TASK_ARN: ${{ steps.start-client.outputs.task-arn }}
      run: |
        echo "Waiting for client task to complete (this may take several hours)..."
        aws ecs wait tasks-stopped --cluster $CLUSTER --tasks $TASK_ARN

        # Check exit code
        EXIT_CODE=$(aws ecs describe-tasks \
          --cluster $CLUSTER \
          --tasks $TASK_ARN \
          --query 'tasks[0].containers[0].exitCode' \
          --output text)

        echo "exit-code=$EXIT_CODE" >> $GITHUB_OUTPUT
        echo "Client task completed with exit code: $EXIT_CODE"

    - name: Stop worker task
      if: always()
      shell: bash
      env:
        CLUSTER: ${{ inputs.ecs-cluster }}
        TASK_ARN: ${{ steps.start-worker.outputs.task-arn }}
      run: |
        if [ -n "$TASK_ARN" ]; then
          echo "Stopping worker task..."
          aws ecs stop-task --cluster $CLUSTER --task $TASK_ARN --reason "Client completed" || true
        fi

    - name: Upload metrics to S3
      id: upload-metrics
      if: always()
      shell: bash
      env:
        RUN_ID: ${{ inputs.run-id }}
        LANGUAGE: ${{ inputs.language }}
        IS_EXPERIMENT: ${{ inputs.is-experiment }}
        S3_BUCKET: ${{ inputs.s3-metrics-bucket }}
        S3_PREFIX: ${{ inputs.s3-metrics-prefix }}
      run: |
        DATE=$(date +%Y-%m-%d)
        S3_PATH="s3://$S3_BUCKET/$S3_PREFIX/is_experiment=$IS_EXPERIMENT/language=$LANGUAGE/date=$DATE/$RUN_ID.parquet"

        # TODO: Retrieve parquet file from ECS task (needs EFS or S3 export from client)
        # For now, log the intended path
        echo "Metrics would be uploaded to: $S3_PATH"
        echo "s3-path=$S3_PATH" >> $GITHUB_OUTPUT

    - name: Check client exit code
      shell: bash
      env:
        EXIT_CODE: ${{ steps.wait-client.outputs.exit-code }}
      run: |
        if [ "$EXIT_CODE" != "0" ]; then
          echo "Client task failed with exit code: $EXIT_CODE"
          exit 1
        fi